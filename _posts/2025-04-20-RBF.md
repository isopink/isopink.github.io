---
layout: single
title: "Lecture 16 : Radial Basis Functions"
---

In this time, we will discuss the RBF. Through this, we will learn how to solve problems using unsupervised learning for data without labels. The discussion will proceed in following four parts: 

1. RBF and nearest neighbors

2. RBF and neural networks

3. RBF and kernel methods

4. RBF and regularization

---

#### 1. Basic RBF model

The basic idea of Radial Basis Function is that every point in the dataset affects the hypothesis. But, this is obvious since we build the hypothesis from the data. However, RBF receives influence in a special way through distance. In other words, one point in the dataset affects other nearby points more than the ones farther away. We can formalize it as below: 

<br>

<div align="center">
Each $(\mathbf{x}_n, y_n) \in \mathcal{D}$ influences $h(\mathbf{x})$ based on $\|\mathbf{x} - \mathbf{x}_n\|$
</div>

<br>

$$
\left\| \mathbf{x} - \mathbf{x}_n \right\|
$$

<br>

That means a single data point $x_n$ in the dataset influences nearby points more strongly than distant ones. This is the core idea behind RBF. This influence is often visualized as a bump centered on the data point, typically shaped like a Gaussian (bell curve) as below: 

![solution](/assets/images/rbf_1.svg) 

The influence is highest near the center and decreases rapidly as we move farther away. Mathematically, the model evaluates each input point $x$ by calculating its distance from every data point $x_n$

