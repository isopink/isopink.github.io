---
layout: single
title: "Lecture 5 : Effective number of hypothesis"
---


In this time, we will talk about how to reduce the number of hypothesis, $M$ which we discussed in [<u>Lecture 2</u>.](https://isopink.github.io/Is-Learning-Feasible/)  The discussion will proceed in the following three parts :


1. Where did the $M$ come from? 

2. Ilustrative examples 

3. Break point 

---

#### 1. Where did the $M$ come from? 

<br>

$$
\mathbb{P}\left[ \lvert E_{\text{in}} - E_{\text{out}} \rvert > \epsilon \right] \leq 2M e^{-2\epsilon^2 N}
$$

<br>

This is the inequality we discussed in lecture 2. At the end of the Lecture 2, i promised to make M tighter. This is the right time to do that. 
