---
layout: single
title: "Lecture 9 : The Linear Model II"
---

In this time, We will discuss the rest of [Linear Model](https://isopink.github.io/Linear-Model-L/). The discussion will proceed in the following three parts:

1. Review of Nonlinear transforms

2. Logistic Regression

3. Error measure of Logistic Regression

4. Gradient Descent

---

#### 1. Review of nonlinear transforms 

We studied nonlinear transformations in [Lecture 3](https://isopink.github.io/Linear-Model-L/), but we didn’t cover everything. Therefore, we would like to add a few more points about nonlinear transformations. 

![solution](/assets/images/lm_1.svg) 

When data isn’t linearly separable, we often apply a feature transform to map $x$ to $\mathcal{Z}$-space. But this increases dimensionality, raising the VC dimension and making generalization harder. So, it’s not always a good idea. Let’s look at two examples.

![solution](/assets/images/lm_2.svg) 

<br>

##### 1.1. Case 1

The first case offers two choices: accept some $E_\text{in}$ with a linear model, or transform to a higher dimension to make the error zero. 

![solution](/assets/images/lm_3.svg) 

We can clearly recognize that transform to a higher-dimension is a disaster. We cannot gerneralize it well. By accepting some $E_\text{in}$, we can generalize it well. 

<br>

##### 1.2. Case 2

![solution](/assets/images/lm_4.svg) 

The second case is definitely non separable. There is no choice but to transform to a higher-dimension. We can think of all possible quadratic curves in $\mathcal{X}$ and describe this feature transform $z=\Phi$ as: 

<br>

$$ \Phi_2(\mathbf{x}) = (1, x_1, x_2, x_1^2, x_1 x_2, x_2^2) $$

<br>

After seeing the result looks like a circle, it’s tempting to remove terms like $x_1$, $x_2$, and $x_1 x_2$ to reduce the VC dimension. But we must not — that’s data snooping. It uses future information and leads to overfitting and poor generalization.

Feature transform is powerful tool. However, with inspection of case $1$ and $2$, It is not always useful tool. The generalization woudl impossible. We have to choose $\Phi$ carefully. 

---

#### 2. Logistic Regression

The core of the linear model is the 'signal' $ s = \mathbf{w}^\mathrm{T} \mathbf{x} $. We have seen two models based on this signal, and we are now going to introduce a third. In Logistic Regression, the signal is converted into a probability through the formula $\theta(s)$:

<br> 

$$ 
\theta(s) = \frac{e^s}{1 + e^s} 
$$ 

<br> 


It is a type of sigmoid function. As $s$ increase, $theta(s)$ approaches $1$, and as $s$ decreases, $\theta(s)$ approaches $0$. Let us consider a concrete example. To predict heart attacks, a linear classifier gives only yes or no. But since risk isn't deterministic, logistic regression is better. It outputs the probability $\theta(s)$, where $s$ is a linear risk score — higher $s$ means higher risk.

Let us first look at the target we want to learn. It is a probability, say of a patient being at risk for heart attack, that depends on the input $\mathbf{x} (the characteristics of the patient). Formally, we are trying to learn the target funtion: 

<br>

$$
f(\mathbf{x}) = \mathbb{P}[y = +1 \mid \mathbf{x}]
$$

<br>

The data doesn’t give $f$ directly, but only samples from the probability $P(y \mid \mathbf{x})$, like patients with or without heart attacks. The data is in fact generated by a noisy target: 

<br>

$$
P(y \mid \mathbf{x}) =
\begin{cases}
f(\mathbf{x}) & \text{for } y = +1; \\
1 - f(\mathbf{x}) & \text{for } y = -1.
\end{cases}
$$

<br>

Our goal is to find $g(\mathbf{x}) = \theta(\mathbf{w}^\mathrm{T} \mathbf{x}) \approx f(\mathbf{x})$. 

---

#### 3. Error measure of Logistic Regression

The standard error measure $e(h(\mathbf{x}), y)$ used in logistic regression is based on the notion of likelihood; how 'likely' is it that we would get this output $y$ from the input $\mathbf{x}$ if the target distribution $P(y \mid \mathbf{x})$ was captured by our hypothesis $h(\mathbf{x})$: 

<br>

$$
P(y \mid \mathbf{x}) =
\begin{cases}
h(\mathbf{x}) & \text{for } y = +1; \\
1 - h(\mathbf{x}) & \text{for } y = -1.
\end{cases}
$$

<br>

We substitute for $h(\mathbf{x})$ by its value $\theta(\mathbf{w}^\mathrm{T} \mathbf{x})$. And use the fact that $\theta(-s) = 1 - \theta(s)$ to get: 

<br>

$$
P(y \mid \mathbf{x}) = \theta(y\, \mathbf{w}^\mathrm{T} \mathbf{x})
$$

<br>

Since the data points are independently generated, the probability of getting all the $y_n$'s in the data set from the corresponding $x_n$'s would be the product: 

<br>

$$
\prod_{n=1}^{N} P(y_n \mid \mathbf{x}_n) = \prod_{n=1}^{N} \theta(y_n\, \mathbf{w}^\mathrm{T} \mathbf{x}_n)
$$

<br>

We want to maximize this probability. Instead, We can minimize: 

<br>

$$
- \frac{1}{N} \ln \left( \prod_{n=1}^{N} \theta(y_n\, \mathbf{w}^\mathrm{T} \mathbf{x}_n) \right)
$$

<br>

$$
= \frac{1}{N} \sum_{n=1}^{N} \ln \left( \frac{1}{\theta(y_n\, \mathbf{w}^\mathrm{T} \mathbf{x}_n)} \right)
$$

<br>

The fact that we are minimizing this qunatity allows us to treat it as an 'error measure'. Substituting $\theta$, We get the final form: 

<br>

$$
E_{\text{in}}(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^{N} 
\underbrace{\ln \left( 1 + e^{-y_n\, \mathbf{w}^\mathrm{T} \mathbf{x}_n} \right)}_{e(h(\mathbf{x}_n), y_n)}
$$

<br> 

---

#### 4. Gradient Descent 


